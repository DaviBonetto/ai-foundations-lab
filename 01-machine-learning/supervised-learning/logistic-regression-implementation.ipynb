{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Binary Classification) from Scratch\n",
    "**Objective:** Implement Binary Logistic Regression using only NumPy (Batch Gradient Descent), including evaluation metrics and decision boundary visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Optional: pandas for display if useful, though main logic is pure numpy\n",
    "# import pandas as pd\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup\n",
    "**Logistic Regression** predicts the probability that an instance belongs to a class (0 or 1).\n",
    "\n",
    "**Model:**\n",
    "$$z = Xw + b$$\n",
    "$$\\hat{y} = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "**Cost Function (Binary Cross-Entropy / Log-Loss):**\n",
    "$$J(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)})]$$\n",
    "\n",
    "**Gradients:**\n",
    "Derivatives for Gradient Descent are surprisingly identical to Linear Regression (due to the choice of Sigmoid + Cross-Entropy):\n",
    "*   $\\frac{\\partial J}{\\partial w} = \\frac{1}{m} X^T (\\hat{y} - y)$\n",
    "*   $\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Data: Two Gaussian Clusters\n",
    "n_samples = 200\n",
    "\n",
    "# Class 0\n",
    "X0 = np.random.randn(n_samples // 2, 2) * 1.5 + [2, 2]\n",
    "y0 = np.zeros((n_samples // 2, 1))\n",
    "\n",
    "# Class 1\n",
    "X1 = np.random.randn(n_samples // 2, 2) * 1.5 + [6, 6]\n",
    "y1 = np.ones((n_samples // 2, 1))\n",
    "\n",
    "X = np.vstack((X0, X1))\n",
    "y = np.vstack((y0, y1))\n",
    "\n",
    "# Shuffle\n",
    "indices = np.arange(n_samples)\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Split Train/Test (80/20)\n",
    "split_idx = int(0.8 * n_samples)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[y_train.flatten() == 0][:, 0], X_train[y_train.flatten() == 0][:, 1], color='red', label='Class 0 (Train)')\n",
    "plt.scatter(X_train[y_train.flatten() == 1][:, 0], X_train[y_train.flatten() == 1][:, 1], color='blue', label='Class 1 (Train)')\n",
    "plt.title('Synthetic Binary Classification Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict_proba(X, w, b):\n",
    "    z = X.dot(w) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    probs = predict_proba(X, w, b)\n",
    "    return (probs >= threshold).astype(int)\n",
    "\n",
    "def log_loss(y_true, y_prob):\n",
    "    # Add epsilon to prevent log(0)\n",
    "    eps = 1e-15\n",
    "    y_prob = np.clip(y_prob, eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def fit_gd(X, y, lr=0.1, epochs=1000, normalize=True):\n",
    "    m, n = X.shape\n",
    "    history = []\n",
    "    \n",
    "    # Normalization Stats\n",
    "    mean, std = np.zeros(n), np.ones(n)\n",
    "    X_train = np.copy(X)\n",
    "    \n",
    "    if normalize:\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0) + 1e-8 # eps for safety\n",
    "        X_train = (X - mean) / std\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward\n",
    "        y_prob = predict_proba(X_train, w, b)\n",
    "        \n",
    "        # Loss\n",
    "        loss = log_loss(y, y_prob)\n",
    "        history.append(loss)\n",
    "        \n",
    "        # Gradients\n",
    "        dw = (1/m) * X_train.T.dot(y_prob - y)\n",
    "        db = (1/m) * np.sum(y_prob - y)\n",
    "        \n",
    "        # Update\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "        \n",
    "    return w, b, history, (mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"name\": \"Small LR, No Norm\", \"lr\": 0.01, \"norm\": False, \"epochs\": 1000},\n",
    "    {\"name\": \"Med LR, Norm\", \"lr\": 0.1, \"norm\": True, \"epochs\": 1000},\n",
    "    {\"name\": \"High LR (Unstable)\", \"lr\": 5.0, \"norm\": True, \"epochs\": 1000}\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "for i, conf in enumerate(configs):\n",
    "    w, b, hist, stats = fit_gd(X_train, y_train, lr=conf['lr'], epochs=conf['epochs'], normalize=conf['norm'])\n",
    "    \n",
    "    # Evaluate on Test\n",
    "    mean, std = stats\n",
    "    X_test_eval = (X_test - mean) / std if conf['norm'] else X_test\n",
    "    \n",
    "    y_pred = predict(X_test_eval, w, b)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    prec, rec, f1 = precision_recall_f1(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Experiment: {conf['name']}\")\n",
    "    print(f\"  Final Acc: {acc:.4f} | Prec: {prec:.2f} | Rec: {rec:.2f} | F1: {f1:.2f}\")\n",
    "    print(f\"  Final Loss: {hist[-1]:.4f}\\n\")\n",
    "    \n",
    "    # Keep best normalized model for visualization\n",
    "    if conf['norm'] and conf['lr'] == 0.1:\n",
    "        best_model = (w, b, stats)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(hist)\n",
    "    plt.title(f\"{conf['name']} (Acc: {acc:.2f})\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model is None:\n",
    "    print(\"Run experiments first to get the best model.\")\n",
    "else:\n",
    "    w_star, b_star, stats_star = best_model\n",
    "    mean, std = stats_star\n",
    "    \n",
    "    # Create a meshgrid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    \n",
    "    # Normalize meshgrid points\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points_norm = (grid_points - mean) / std\n",
    "    \n",
    "    # Predict\n",
    "    Z = predict(grid_points_norm, w_star, b_star)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "    \n",
    "    # Plot class 0 and 1\n",
    "    plt.scatter(X[y.flatten()==0][:, 0], X[y.flatten()==0][:, 1], c='red', edgecolor='k', label='Class 0')\n",
    "    plt.scatter(X[y.flatten()==1][:, 0], X[y.flatten()==1][:, 1], c='blue', edgecolor='k', label='Class 1')\n",
    "    \n",
    "    plt.title(\"Decision Boundary (Normalized GD Model)\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best model on test set\n",
    "X_test_norm = (X_test - mean) / std\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "\n",
    "print(\"Threshold Performance Analysis:\")\n",
    "print(\"-\"*40)\n",
    "for thr in thresholds:\n",
    "    y_pred_thr = predict(X_test_norm, w_star, b_star, threshold=thr)\n",
    "    prec, rec, _ = precision_recall_f1(y_test, y_pred_thr)\n",
    "    print(f\"Threshold {thr}: Precision: {prec:.2f} | Recall: {rec:.2f}\")\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Insight: Lowering threshold increases Recall (catches more positives) but drops Precision (more false alarms).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Takeaways\n",
    "*   **Normalization:** Crucial for efficient gradient descent, especially when features have different scales or non-zero means.\n",
    "*   **Convergence:** With appropriate LR (0.1) and normalization, loss decreases smoothly.\n",
    "*   **High Learning Rate:** Can cause oscillation or overshoot, though Log-Loss is generally convex (unlike MSE for classification).\n",
    "*   **Log-Loss vs MSE:** Log-Loss is the standard for classification because it convexifies the error surface when using Sigmoid, guaranteeing a global minimum.\n",
    "*   **Limitations:** Linear decision boundary. Cannot solve XOR or complex non-linear separations without feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "*   Explore **Support Vector Machines (SVM)** for better margin maximization and kernel tricks.\n",
    "*   [Go to SVM Notebook](./svm-kernels.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
